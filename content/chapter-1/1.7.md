---
title: "1.7 Modeling with Functions"
description: "Every spring, hundreds of people come to the Great Plains region of the United States in an attempt to get as close as possible to one of natureâ€™s most violent events: a tornado. "
slug:
image: "tornado.jpg"
draft: false
---

{{% imgcap file="/img/chapter-1/nikolas-noonan-682177-unsplash.jpg" title="Tornado photo by Nikolas Noonan on Unsplash" source="https://unsplash.com/photos/fQM8cbGY6iQ"%}}

## Introduction
Every spring, hundreds of people come to the Great Plains region of the United States in an attempt to get as close as possible to one of nature's most violent events:  a tornado.  While some go to "Tornado Alley" just for the thrill, most professional storm chasers have a different goal.  What they want is data: scientific measurements that can only be found inside real tornadoes.

Scientists and university researchers, like those at NOAA's National Severe Storms Laboratory, hope to use that data to create mathematical models that will help them understand the inner workings of tornadoes and how they form.


## Understand the Modeling Process
When we speak of a **mathematical model**, what exactly are we talking about?  A model is simplified representation of a real world object.  It often takes the form of a table of values, a graph, or an equation.  Mathematical models are found in nearly every field of study and are useful when it is not feasible, economical, practical, or safe to work with the real item.  

Once a model has been created, we can use the rules of mathematics to discover things about its mathematical behavior. Those discoveries can, in turn, can be used to make predictions and give insight about how the real world object might behave.

![](/img/chapter-1/modeling_diagram.svg#center)

Further observations and adjustments help the model look more like how the real world looks.


## Scatterplots
Many physical laws, like the law of gravity, were discovered by gathering data and looking for patterns.  One of our primary tools for visualizing data is the **scatterplot**.  A scatterplot is nothing more than pairs of data plotted as points on a grid.  

For example, researchers from Purdue University analyzed 1285 tornadoes in Indiana from 1950 to 2012.{{% sidenote "tornado citation" %}}See the paper by Olivia Kellner and Dev Niyogi in the [American Meteorological Society's Earth Interactions journal, volume 18 no. 10 (2014).](https://doi.org/10.1175/2013EI000548.1){{% /sidenote %}}  One set of data compared the number of tornadoes observed at different hours of the day.

![](/img/chapter-1/tornado_time.svg#center)

The scatterplot shows a clear pattern in the data and suggests that most tornadoes form late in the afternoon.  This is a well known result that follows from the fact that by mid afternoon the sun has heated the ground and the atmosphere enough to produce thunderstorms.

The red curve is a model of the data and could be used to make predictions.


## Interpolation and Extrapolation
Models can be used to make estimations in two different ways. Making a prediction outside of a data set is called **extrapolation**.  Estimating a value that is in between known values is **interpolation**.

For example, if we knew the number of tornadoes in 1900 and in 2000, then predicting how many will happen in 2050 would be an extrapolation, since that value lies outside of the known data.  Extrapolation assumes that an existing trend will continue unchanged into the future, which is never guaranteed.

Estimating the number of tornadoes in the year 1950, however, would be interpolation, since 1950 is between the known values.

{{% check %}}
Suppose that the price of a movie ticket in 2000 and 2010 are known.  Decide if the following would be examples of interpolation or extrapolation.

1. Predicting what the cost of a movie ticket will be in 2050. {{% answer %}}Extrapolation{{% /answer %}}
1. Estimating what the cost of a movie ticket was in 1920. {{% answer %}}Extrapolation{{% /answer %}}
1. Estimating what the cost of a movie ticket was in 2005. {{% answer %}}Interpolation{{% /answer %}}
{{% /check %}}


## Modeling with Transformations
If we find that a set of data has a shape similar to one of our basic functions, then transformations can be used to shift and stretch that function to make it model the data.  Let's look at a few transformed functions that you might have seen in prior algebra classes.

### Slope-Intercept Form of a Line
To begin, we take the identity function $f(x)=x$ and stretch it vertically by a factor of $\color{blue}{m}$ and shift it vertically $\color{green}{b}$ units.  The result, $y=\color{blue}{m}x+\color{green}{b}$, is known as the **slope-intercept** form for a line, where $\color{blue}{m}$ is the slope and $\color{green}{b}$ is the y-intercept.  The figure below will let you experiment with this equation.

{{% geogebra ratio="50%" id_1="Wr52bKrzTkGnlmob" id_2="hBQsE4O1" id_m="hBQsE4O1" %}}
</br>

### Point-Slope Form of a Line
Another transformed version of the identity function is $y=\color{blue}{m}(x-\color{brown}{x_1})+\color{green}{y_1}$.  

This new equation applies a shift right $\color{brown}{x_1}$ spaces, a vertical stretch by $\color{blue}{m}$, and a vertical shift $\color{green}{y_1}$ spaces.  

The result is a line that passes through the point $(\color{brown}{x_1}, \color{green}{y_1})$ and has a slope of $\color{blue}{m}$.  We call this the **point-slope** form of a line.  You can experiment with this equation in the figure below.

{{% geogebra ratio="50%" id_1="kDqggaOWaZNpd7Ni" id_2="PdeIue6n" id_m="PdeIue6n" %}}
</br>

### Vertex Form of a Quadratic
Lastly, consider $y=\color{blue}{a}(x-\color{brown}{h})^2+\color{green}{k}$, which is a transformed version of the square function.  

The horizontal and vertical shifts move the vertex to the point $(\color{brown}{h}, \color{green}{k})$ and the vertical stretch by a factor of $\color{blue}{a}$ affects the concavity of the graph.  

This equation is often referred to as the **vertex form** of a quadratic function.  You can identify the three transformations in the figure below.

{{% geogebra ratio="50%" id_1="BBDfruwxgd3VVqyG" id_2="uTrJWh1K" id_m="uTrJWh1K" %}}
</br>

### Another Tornado Data Set
Let's take a look at another set of data about tornadoes.  Here we are given the percentage of tornadoes touching down within several kilometers of populated areas.

{{% geogebra ratio="50%" id_1="6XcJvVUnACwrTb4z" id_2="mrcsehab" id_m="j64zgw6h" %}}

This scatterplot reveals a strong linear trend with the percentage of observed tornadoes increasing further away from the city or town center, with the equation $y=\color{blue}{2.84}x+\color{green}{0.14}$ being a good model for the data.  

If we use our model to extrapolate back to a distance of $0$ kilometers it seems that there is $0\\%$ chance of seeing a tornado, which might suggest that people in cities are safer than those in rural areas.  But since cities cover a small fraction of the land in any state, the opposite may actually be true.  

Other research suggests that the slower wind and hotter air in urban areas can actually increase the tornado-genesis process.  Tornadoes are certainly not diverted by any structure or building.  They have been know to hit large cities, pass over rivers, climb hills and cross canyons.  [The safest place is in a fortified tornado shelter.](https://www.spc.noaa.gov/faq/tornado/#Safety "NOAA's tornado safety guidelines")

The lesson here is that even when the data has an obvious pattern, we must be careful and take time to find and consider other underlying factors before we make predictions or conclusions from our model.


##  Aligning & Scaling Data
When making a scatterplot we must decide which quantity will be represented by the independent variable and which is the dependent variable.  It may also be helpful to align and/or scale the data.

To demonstrate how this works, we will use the following raw data from the U.S. Department of Agriculture to create a scatterplot.

![](/img/chapter-1/apple_data_raw.png#center)

With this data, it seems reasonable that the year is independent and the price is dependent.  Since we don't want a graph that is 2009 units wide, we choose to **align** the years by converting them to years since 2000.  This is done by subtracting 2000 from each year.  

And we might want to convert the price to *dollars* per pound rather than *cents* per pound.  To change the **scale** of the prices we divide each price by 100.  The result of aligning the years and scaling the prices is shown below.

![](/img/chapter-1/apple_data_aligned.png#center)

Now that we have aligned and scaled the apple data, let's take a look at the scatterplot and compare its shape with the shapes of the six basic functions that we know.  Does it look like the identity function or the square function? Perhaps it looks like the reciprocal or the cube root function?

![](/img/chapter-1/apple_data_graph.svg#center)

Since this data appears linear, we should be able to model it with a transformed version of the identity function $f(x)=x$.  Specifically, we will use the slope-intercept form of a line $y = \color{blue}{m} x + \color{green}{b}$.

All that remains is to find values of $\color{red}{m}$ and $\color{green}{b}$ that make the model fit the data as closely as possible.

In the figure below, you are free to change both the slope $\color{red}{m}$ and the y-intercept $\color{green}{b}$ until you find a line that fits the data.  Make a note of your equation before continuing.

{{% geogebra ratio="50%" id_1="XNmissvYwqQV8RC8" id_2="m9XFVxlH" id_m="m9XFVxlH" %}}

You may have had trouble finding just one line that fit well.  In fact, good arguments could be made for several lines.  However, the line that is as close as possible to each point is the line $\color{blue}{y} = \color{red}{0.04}x + \color{green}{0.86}$.

Where did this equation come from and how do we know it is the best?  Well, that's a great question would take a few weeks in a statistics course to explain fully.  For now, it's enough to know that most graphing calculators have a built-in programs that fit equations to data.  That process is called *least squares regression*, and we will look at it later in this section.  


## Construct Models
Now that we have an equation, $\color{blue}{y} = \color{red}{0.04}x + \color{green}{0.86}$, it's time to turn that into an actual model.

Throughout this text, a model will consist of a function along with a description of its the variables and their units of measure.  Without an accurate description, the function itself is meaningless since there would be no way to relate it to the real world.

Since our independent variable is time in years since 2000, we take the liberty of using $t$ in place of $\color{blue}{x}$.  

Similarly, using $p$ instead of $\color{blue}{y}$ will help us remember that the dependent variable represents the price of apples.  We are now ready to write our model.

> According to data provided by the U.S. Department of Agriculture, the price $p$ of apples per pound can be modeled by the function
> \[ p(t) = 0.04t + 0.86 \]
> where $t$ is the time in years since 2000.

This model could be used to predict the price of a pound of apples in the year 2030.  To do this we simply evaluate the function for $t=30$ (remember, $t$ is years *since* 2000.)

\[
  p(30) = 0.04(30) + 0.86 = 2.06
\]

Thus, our model predicts the average price of apples will be $2.06 in the year 2030.  How accurate is that?  We'll have to wait and see.


## Modeling with Technology
{{% imgcap file="/img/chapter-1/horses-61158_1280.jpg" title="Photo Steppinstars from Pixabay " source="https://pixabay.com/images/id-61158/"%}}

We now turn our attention to another scenario.  Throughout the grasslands of Nevada live herds of wild horses known as "mustangs".  Since 1971, the Bureau of Land Management has been monitoring the number of mustangs and the land's capacity to support them.  When the number of horses exceeds an appropriate management level, the BLM gathers animals from overpopulated herds and makes them available for adoption.

Every year the BLM conducts aerial surveys in an effort to count each horse.  A functional model of that data can be used to predict the future size of a herd, helping the BML anticipate when it might be necessary to prepare some mustangs for adoption.

The table below gives the total number of mustangs in Nevada since 2000.

![](/img/chapter-1/horse_data.png)
Since the population decreased and then started to increase, it seems reasonable that a transformation of the square function $f(x)=x^{2}$ might fit the data.  

In the figure below the vertex form of a quadratic is shown along with the data.  Adjust the values of $\color{blue}{a}$, $\color{brown}{h}$ and $\color{green}{k}$ until you find a good fit for the data.

{{% geogebra ratio="50%" id_1="NYMIg0eN3w5XIZtN" id_2="FdLFe4II" id_m="FdLFe4II" %}}

With data sets like this one it is hard to know which combination of transformations will make the curve fit the data the best.  In instances like this it is often best to let technology find the equation for us.

Most graphing calculators have a quadratic regression program `QuadReg` that finds a quadratic equation fitting the data.  Here we will show the steps for the Texas-Instruments 83/84 series of calculators.  

We start by entering the data into the calculator by pressing the `STAT` button and selecting `1: Edit`.

![](/img/chapter-1/horse_regression_1.png#center)

The data is entered into the `L1` and `L2` lists.

![](/img/chapter-1/horse_regression_2.png#center)

To view the scatterplot, press `2ND` and `Y=` to enter the `STAT PLOTS` menu,  then select the first plot and make sure it is turned on.

![](/img/chapter-1/horse_regression_3.png#center)

Using `9:ZoomStat` in the `ZOOM` menu gives a good viewing window for the data.

![](/img/chapter-1/horse_regression_4.png#center)

Once we have confirmed the shape of the data, we go back to the `STAT` menu and this time choose the `CALC` tab.

![](/img/chapter-1/horse_regression_5.png#center)

This reveals all of the regression models built into the calculator, letting us choose the model that we think visually matches the shape of the data.  Since this data looks like the square function, we choose `5: QuadReg`.  If the data had looked like a line then `4: LinReg(ax+b)` would have been a good choice.

After running `5: QuadReg` we are shown the equation that fits the data.

![](/img/chapter-1/horse_regression_6.png#center)

The result is given in the standard form $y = a x^{2} + b x + c$ rather than in the vertex form we used when trying to fit the data by hand.  Copying this equation into the graphing window shows that it fits the data reasonably well.

![](/img/chapter-1/horse_regression_7.png#center)

We could now use the equation $y=239.8x^2-3147.9x+24397.8$ as the basis for a model of the wild mustang population in Nevada.

It bears repeating that a mathematical model is not the same as the real object, nor does it control the behavior of the real thing.  For instance, this model might *predict* the future number of wild mustangs, but it is in no way a guarantee of what will happen.


## Modeling with Piecewise-Defined Functions
{{% imgcap file="/img/chapter-1/pompidou_1.jpg" title="Photo by Yann Caradec on Flickr" source="https://www.flickr.com/photos/la_bretagne_a_paris/5995530090"%}}

The Pompidou Center in Paris has an amazing escalator. Designed by Italian architect Renzo Piano and British designer Richard Rogers, the 6 story escalator is encased in a glass tube and attached to the outside of the building!

The Pompidou escalator is not a single straight line, but rather several small lines pieced together.  It's an example of a new type of function which we'll call **piecewise-defined** functions.  For instance, to model the Pompidou escalator we shift and stretch several pieces of the identity function and connect them together with horizontal line segments.

![](/img/chapter-1/pompidou_model.gif)

**Piecewise-defined** functions, such as this, give us a lot more flexibility when creating models.  No longer are we required to find a single function; we are now free to construct models in multiple pieces.

When writing piecewise functions, we list the equations for each piece and then specify where each is used.  Consider, for example, the path a bounding ball.  

![https://people.rit.edu/andpph/photofile-misc/stroboscope/bouncing-ball-7791m.jpg](/img/chapter-1/piecewise_bounce.gif#center)

Each bounce is an individual parabola, with its own equation, and its own limited domain.  The piecewise function for this particular ball is

\[ f(x)=\begin{cases}
      -(x+2)(x-2) & \text{if } & 0 \leq x \leq 2 \newline
      -1.2(x-2)(x-5) & \text{if } & 2 <  x \leq 5 \newline
      -1.8(x-5)(x-7) & \text{if } & 5 < x \leq 7
   \end{cases}
\]

To find a value such as $f(4)$, we first compare our x-value $4$ with the three inequalities.  Since $4$ would fit in $2<x \leq 5$, we must use the second equation.  Thus, $f(4)=-1.2(4-2)(4-5) =2.4$.

{{% check %}}
Use the piecewise function above to evaluate the following:

1. $f(0)${{% answer %}}$-(0+2)(0-2) = 4${{% /answer %}}
1. $f(2)${{% answer %}}$-(2+2)(2-2)=0${{% /answer %}}
1. $f(6)${{% answer %}}$-1.8(6-5)(6-7)=1.8${{% /answer %}}
{{% /check %}}


## Looking Ahead
In the chapters that follow, we will encounter new functions that increase our ability to model real life scenarios, but the basic process will be the same. We will always start by comparing the properties of the data with the behaviors of functions we know.  Then we use transformations and/or technology to fit a model to the data.  The model can be used to interpolate and/or extrapolate unknown values.

If the model predicts unreasonable values that do not make any sense, then we should try to explain how we know the result is an error and why it might have occurred.  An analysis of the errors can often lead to the construction of a more robust model.  

And while our models will never be perfect, there is a good chance that they might be accurate enough to be useful.  Physicist Eugene Wigner has referred to the predictive nature of mathematics, especially in the natural sciences, as the *"unreasonable effectiveness of mathematics."*  This is something that we will see more of in the next chapters.
